{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import helpers_preorder as hp\n",
    "import helpers_datasets as hd\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "BASELINE = \"baseline\"\n",
    "KAN = \"kan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c23ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fit_kan_classifier(n_estimators: int, Xtr: np.ndarray, ytr: np.ndarray):\n",
    "    params = {\n",
    "        \"f\": None,\n",
    "        \"verbose\": False,\n",
    "        \"get_f_learner\": lambda X: hp.ClassifierProbabilityLearner(clf_class=DecisionTreeClassifier),\n",
    "    #     \"get_f_learner\": lambda X: hp.ClassifierProbabilityLearner(clf_class=RandomForestClassifier),\n",
    "    # #     \"get_f_learner\": lambda X: hp.LinearOrderingLossLearner(\n",
    "    # #         learning_rate=0.02,\n",
    "    # #         output_dimension=10,\n",
    "    # #         num_columns=X.shape[-1],\n",
    "    # #         epochs=1000,\n",
    "    # #         batches_per_epoch=1,\n",
    "    # #         verbose=False),\n",
    "    #     \"get_f_learner\": lambda X: hp.NetworkOrderingLossLearner(\n",
    "    #         num_layers=0,\n",
    "    #         learning_rate=0.02,\n",
    "    #         output_dimension=10,\n",
    "    #         epochs=1000,\n",
    "    #         batches_per_epoch=1,\n",
    "    #         verbose=False),\n",
    "        \"get_kind\": lambda: np.random.choice([hp.PreorderClassifier.RAN, hp.PreorderClassifier.LAN])\n",
    "    }\n",
    "    clf = BaggingClassifier(\n",
    "        hp.PreorderClassifier(**params),\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=int(Xtr.shape[1] * 0.25),\n",
    "        n_jobs=10\n",
    "    )\n",
    "    clf.estimator_params = list(params.keys())\n",
    "    for k, v in params.items():\n",
    "        setattr(clf, k, v)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def get_fit_rf_classifier(n_estimators: int, Xtr: np.ndarray, ytr: np.ndarray):\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def get_experiment_results(Xtr: np.ndarray, ytr: np.ndarray, Xte: np.ndarray, yte: np.ndarray):\n",
    "    results = defaultdict(lambda: defaultdict(float))\n",
    "    for n_estimators in [10, 50, 100]:\n",
    "        for model_name, get_fit_model in [(BASELINE, get_fit_rf_classifier), (KAN, get_fit_kan_classifier)]:\n",
    "            model_key = \"{}_{}\".format(model_name, n_estimators)\n",
    "            print(model_key)\n",
    "            clf = get_fit_model(n_estimators=n_estimators, Xtr=Xtr, ytr=ytr)\n",
    "            predictions = clf.predict(Xte)\n",
    "            results[model_key][\"tpr\"] = hp.true_positive_rate(yte, predictions)\n",
    "            results[model_key][\"tnr\"] = hp.true_negative_rate(yte, predictions)\n",
    "            results[model_key][\"roc_auc\"] = roc_auc_score(yte, predictions)\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9d58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "included_classes = {0:False, 6:True} # Tshirt = 0, Shirt = 6\n",
    "X_mnist_train, y_mnist_train_raw, X_mnist_test, y_mnist_test_raw = hd.get_mnist_dataset(\n",
    "    included_classes=included_classes.keys(), num_train_images=-1, num_test_images=-1)\n",
    "y_mnist_train = np.array([included_classes[y] for y in y_mnist_train_raw])\n",
    "y_mnist_test = np.array([included_classes[y] for y in y_mnist_test_raw])\n",
    "\n",
    "mnist_results = get_experiment_results(Xtr=X_mnist_train, ytr=y_mnist_train, Xte=X_mnist_test, yte=y_mnist_test)\n",
    "pd.DataFrame(mnist_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accd9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
